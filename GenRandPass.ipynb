{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Header Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import re \n",
    "import random\n",
    "\n",
    "# Keras 2.2.4/tensorflow 1.14.0 -> Version matching for local machine\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv files of Passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row\n"
     ]
    }
   ],
   "source": [
    "txtfile = \"passes_name_8.csv\"\n",
    "import csv\n",
    "with open(txtfile,'rt')as f:\n",
    "  data = csv.reader(f)\n",
    "  for row in data:\n",
    "        print(\"row\")\n",
    "passes=row\n",
    "# print(len(passes))\n",
    "# print(passes)\n",
    "cplsryPass=[\"mem2reg\",\"loop-simplify\",\"loop-rotate\",\"indvars\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function generates set of passes for KTransFormations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genPasses(KTfms,maxPasses):\n",
    "    passList = []\n",
    "    # Number of Transformation Per Program\n",
    "    for i in range(KTfms):\n",
    "        passCount = random.randint(1,maxPasses)\n",
    "        passString = \"\"\n",
    "        uniqueCheck=[]\n",
    "        # Number of Passes in each Transformation\n",
    "        for j in range(passCount):\n",
    "            passNo = random.randint(0,len(passes)-1)\n",
    "            \n",
    "            # Not compulsary pass.\n",
    "            if passes[passNo] not in cplsryPass:\n",
    "                if passes[passNo] not in uniqueCheck:\n",
    "                    uniqueCheck.append(passes[passNo])\n",
    "                    \n",
    "                    # Add all compulsary passes.\n",
    "                    for cpPass in cplsryPass:\n",
    "                        if cpPass not in uniqueCheck:\n",
    "                            # If New add in string and uniqueCheckList.\n",
    "                            uniqueCheck.append(cpPass)\n",
    "                            \n",
    "            # 4 Compulsary pass [\"mem2reg\",\"loop-simplify\",\"loop-rotate\",\"indvars\"].\n",
    "            else:\n",
    "                if passes[passNo] == \"mem2reg\" and passes[passNo] not in uniqueCheck:\n",
    "                    uniqueCheck.append(passes[passNo])\n",
    "                    \n",
    "                if passes[passNo] == \"loop-simplify\" and passes[passNo] not in uniqueCheck:\n",
    "                    uniqueCheck.append(passes[passNo])\n",
    "                    \n",
    "                if passes[passNo] == \"loop-rotate\" and passes[passNo] not in uniqueCheck:\n",
    "                    uniqueCheck.append(passes[passNo])\n",
    "                    \n",
    "                    # Adding passes required for Loop rotate pass.\n",
    "                    if \"loop-simplify\" not in uniqueCheck:\n",
    "                        uniqueCheck.append(\"loop-simplify\")\n",
    "                        \n",
    "                if passes[passNo] == \"indvars\" and  passes[passNo] not in uniqueCheck:\n",
    "                    uniqueCheck.append(passes[passNo])\n",
    "                    \n",
    "                    # Adding passes required for indvars pass.\n",
    "                    if \"mem2reg\" not in uniqueCheck:\n",
    "                        uniqueCheck.append(\"mem2reg\")\n",
    "                    if \"loop-simplify\" not in uniqueCheck:\n",
    "                        uniqueCheck.append(\"loop-simplify\")\n",
    "                    if \"loop-rotate\" not in uniqueCheck:\n",
    "                        uniqueCheck.append(\"loop-rotate\")\n",
    "#         print(uniqueCheck)\n",
    "        passList.append(uniqueCheck)\n",
    "    return passList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate opt command and run on passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genVector(LL_FILE_ip,KTfms,maxPasses):\n",
    "    PATH = \"/home/gagandeep/Desktop/work/polybench/Utilities_IR2Vec/Utilities/\"\n",
    "    PATH_OPT = PATH + \"opt\"\n",
    "    PATH_SO_DIR = PATH + \"IR2Vec-RD.so\"\n",
    "    PATH_EMBD_DIR = PATH + \"embedding_300D_TransE_1500ep_Quant.txt\"\n",
    "#     LL_FILE_PATH = \"/home/gagandeep/Desktop/work/polybench/pb_ll/2mm/O0/\"\n",
    "#     LL_FILE_NAME = \"O0_2mm.ll\"\n",
    "#     LL_FILE = LL_FILE_PATH + LL_FILE_NAME\n",
    "    # LL_FILE_ip is a pair with location and filename of LL-file.\n",
    "    LL_FILE = os.path.join(LL_FILE_ip[0], LL_FILE_ip[1])\n",
    "    OP_FILE_NAME_txt = \"vectors/\" + LL_FILE_ip[1]+\".txt\"\n",
    "    cmd=[PATH_OPT,\"-load\",PATH_SO_DIR,\"-IR2Vec_RD\",\"-file\",PATH_EMBD_DIR,\n",
    "               \"-bpi\",\"1\",\"-class\",\"-1\",\"-of\",OP_FILE_NAME_txt,\"-level\",\"f\",\n",
    "               \"-wo\",\"1\",\"-wt\",\"0.5\",\"-wa\",\"0.2\",LL_FILE]\n",
    "\n",
    "    transCmd = []\n",
    "    for passSet in genPasses(KTfms,maxPasses):\n",
    "        transCmd = list(cmd)        \n",
    "        for eachPass in passSet:\n",
    "            transCmd.append(\"-\"+eachPass)\n",
    "    #     print(transCmd)\n",
    "        temp = subprocess.Popen(transCmd, stdout = subprocess.PIPE)\n",
    "\n",
    "    # output = str(temp.communicate()) \n",
    "\n",
    "    # output = output.split(\"\\n\") \n",
    "    # output = output[0].split('\\\\')\n",
    "    # # for val in output:\n",
    "    # #     print(val)\n",
    "\n",
    "    # res = [] \n",
    "\n",
    "    #     # iterate through the output \n",
    "    #     # line by line \n",
    "    # for line in output: \n",
    "    #     res.append(line) \n",
    "\n",
    "    # # print the output \n",
    "    # for i in range(1, len(res) - 1): \n",
    "    #     print(res[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vectors for all LL-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ll_files/adc.ll\n",
      "./ll_files/adc.ll\n",
      "./ll_files/adc.ll\n",
      "./ll_files/adc.ll\n"
     ]
    }
   ],
   "source": [
    "def call2genVec():\n",
    "    llFiles = []\n",
    "    for dirname, _, filenames in os.walk('./ll_files'):\n",
    "        for filename in filenames:\n",
    "            llFiles.append([dirname,filename])\n",
    "\n",
    "    for eachFile in llFiles:\n",
    "        genVector(eachFile,10,15)\n",
    "        print(os.path.join(val[0], val[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the vectors to create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -1.822447 -1.919357  0.901833 -4.671315 -0.961689  1.243988  0.938743   \n",
      "\n",
      "        7         8         9    ...       290       291       292       293  \\\n",
      "0 -0.440845  0.987527 -2.442327  ...  1.145447  2.829992 -0.443599 -0.744863   \n",
      "\n",
      "        294       295      296       297       298       299  \n",
      "0 -0.669255  0.450204  1.32371  1.607742 -0.243377  0.281935  \n",
      "\n",
      "[1 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "IRVec = []\n",
    "vecFiles = []\n",
    "class_label=0\n",
    "for dirname, _, filenames in os.walk('./vectors'):\n",
    "    for filename in filenames:\n",
    "        vecFiles.append([dirname,filename])\n",
    "for eachFile in vecFiles:\n",
    "    txtfile = os.path.join(eachFile[0], eachFile[1])\n",
    "    traindf = pd.read_csv(txtfile,delimiter=\"\\t\",header=None)\n",
    "    traindf = traindf.dropna(axis=1)\n",
    "#     traindf = traindf.drop(traindf.columns[:2],axis=1)\n",
    "#     print(traindf.shape[0])\n",
    "#     print(traindf.iloc[199,:])\n",
    "    # Count of Different Functions\n",
    "    functCount = -1\n",
    "    for index,Count in enumerate(traindf.iloc[:,0]):\n",
    "        if Count == traindf.iloc[0,0]:\n",
    "            if functCount == -1:\n",
    "                functCount = index\n",
    "            else:\n",
    "                functCount = index\n",
    "                break\n",
    "#     print(functCount)\n",
    "    traindf = traindf.drop(traindf.columns[:2],axis=1)\n",
    "#     print(traindf.iloc[199,:])\n",
    "#     print(type(traindf.iloc[]))\n",
    "    for index,dataPoint in enumerate(traindf.iloc[:]):\n",
    "#         new_data_point = dataPoint.values.reshape(1,dataPoint.size)\n",
    "#         new_data_point=pd.DataFrame(dataPoint)\n",
    "#         print(traindf.iloc[dataPoint,:])\n",
    "        new_data_point = traindf.iloc[dataPoint,:]\n",
    "        new_data_point = new_data_point.values.reshape(1,new_data_point.size)\n",
    "        new_data_point= pd.DataFrame(new_data_point)\n",
    "        \n",
    "        if index == 0:\n",
    "            temp = new_data_point\n",
    "#                 labels.append(class_label)\n",
    "\n",
    "        else :\n",
    "            temp = pd.concat([temp, new_data_point])\n",
    "#                 labels.append(class_label)\n",
    "    \n",
    "        print(temp)\n",
    "        break\n",
    "        \n",
    "#         print(new_data_point)\n",
    "#         print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gagandeep/Desktop/work/polybench/Utilities_IR2Vec/Utilities/opt -load /home/gagandeep/Desktop/work/polybench/Utilities_IR2Vec/Utilities/IR2Vec-RD.so -IR2Vec_RD -file /home/gagandeep/Desktop/work/polybench/Utilities_IR2Vec/Utilities/embedding_300D_TransE_1500ep_Quant.txt -bpi 1 -class -1 -of O0_2mm.ll.txt -level f -wo 1 -wt 0.5 -wa 0.2 /home/gagandeep/Desktop/work/polybench/pb_ll/2mm/O0/O0_2mm.ll -gvn -mem2reg -loop-simplify -loop-rotate -indvars -bb-vectorize -loop-extract-single -aggressive-instcombin -loop-deletion -ipsccp -inline \n"
     ]
    }
   ],
   "source": [
    "a = \"\"\n",
    "tra = ['/home/gagandeep/Desktop/work/polybench/Utilities_IR2Vec/Utilities/opt', '-load', '/home/gagandeep/Desktop/work/polybench/Utilities_IR2Vec/Utilities/IR2Vec-RD.so', '-IR2Vec_RD', '-file', '/home/gagandeep/Desktop/work/polybench/Utilities_IR2Vec/Utilities/embedding_300D_TransE_1500ep_Quant.txt', '-bpi', '1', '-class', '-1', '-of', 'O0_2mm.ll.txt', '-level', 'f', '-wo', '1', '-wt', '0.5', '-wa', '0.2', '/home/gagandeep/Desktop/work/polybench/pb_ll/2mm/O0/O0_2mm.ll', '-gvn', '-mem2reg', '-loop-simplify', '-loop-rotate', '-indvars', '-bb-vectorize', '-loop-extract-single', '-aggressive-instcombin', '-loop-deletion', '-ipsccp', '-inline']\n",
    "for val in tra:\n",
    "    a = a + val +\" \"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
